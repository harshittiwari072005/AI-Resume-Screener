{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e9593a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\ProgramData\\\\anaconda3\\\\envs\\\\machinelearning\\\\python.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7328d6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root to Python path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "print(\"Project root added to path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7881280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (3.0.1)\n",
      "Requirement already satisfied: docx2txt in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (0.9)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (3.8.11)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (0.21.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy) (2.1.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: wrapt in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (1.14.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 2.3 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 2.6/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 2.9 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.2/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.5/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.8/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.6/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 3.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 3.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 2.9 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/12.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.0 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2 docx2txt\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40571ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser.resume_parser import parse_resume\n",
    "from nlp.text_preprocessing import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f4249ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harshit tiwari \n",
      "   harshittiwari         linkedinharshit tiwari         \n",
      " education srm institute science technology kattankulathur expect     \n",
      " bachelor technology computer science specialization big datum analytic cumulative gpa         \n",
      " technical skill programming language python web html css framework django library panda numpy scikit learn matplotlib seaborn database mysql sqlite tool git github google colab code jupyter notebook excel project house price prediction github build model pred\n"
     ]
    }
   ],
   "source": [
    "raw_text = parse_resume(\"../uploads/sample_resume.pdf\")\n",
    "cleaned_text = clean_text(raw_text)\n",
    "\n",
    "print(cleaned_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5b8fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TEXT LENGTH: 1712\n",
      "CLEANED TEXT LENGTH: 1420\n"
     ]
    }
   ],
   "source": [
    "print(\"RAW TEXT LENGTH:\", len(raw_text))\n",
    "print(\"CLEANED TEXT LENGTH:\", len(cleaned_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d8e9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Skills: ['numpy', 'mysql', 'django', 'css', 'sql', 'scikit', 'html', 'python']\n"
     ]
    }
   ],
   "source": [
    "from nlp.skill_extraction import extract_skills\n",
    "resume_skills = extract_skills(cleaned_text)\n",
    "print(\"Extracted Skills:\", resume_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c078bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"We are looking for a Python Django developer with strong SQL skills.\n",
    "Experience with REST APIs and AWS is preferred.\n",
    "Knowledge of HTML, CSS, and JavaScript is a plus.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b32b11",
   "metadata": {},
   "source": [
    "CLEANING THE JOB DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f4b2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANED JOB DESCRIPTION look python django developer strong sql skill experience rest apis aw preferred knowledge html css javascript plus\n"
     ]
    }
   ],
   "source": [
    "cleaned_jd= clean_text(job_description)\n",
    "print(\"CLEANED JOB DESCRIPTION\", cleaned_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1167070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted JD Skills: ['java', 'javascript', 'django', 'rest', 'css', 'sql', 'api', 'html', 'python']\n"
     ]
    }
   ],
   "source": [
    "jd_skills = extract_skills(cleaned_jd)\n",
    "print(\"Extracted JD Skills:\", jd_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9248c",
   "metadata": {},
   "source": [
    "CREATING COMMON SKILLS BETWEEN JOB DESCRIPTION AND RESUME AND CALCULATING ITS OVERLAP SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accacf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Skills: {'django', 'css', 'sql', 'html', 'python'}\n",
      "Skill Overlap Score: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "common_skills = set(resume_skills).intersection(set(jd_skills))\n",
    "\n",
    "skill_overlap_score = len(common_skills) / len(jd_skills)\n",
    "\n",
    "print(\"Common Skills:\", common_skills)\n",
    "print(\"Skill Overlap Score:\", skill_overlap_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbf762",
   "metadata": {},
   "source": [
    "# Load Dataset Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16e714e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resumes loaded: 3500\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "resumes = []\n",
    "\n",
    "with open(\"../data/resumes_dataset.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line.strip())\n",
    "        resumes.append(data[\"Text\"])\n",
    "\n",
    "print(\"Total resumes loaded:\", len(resumes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d37ef32",
   "metadata": {},
   "source": [
    "**CLEANING THE LOADED RESUMES TEXT USING OUR FUNCTION OR THE PIPELINE WE MADE **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c0be497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cleaned resumes: 3500\n"
     ]
    }
   ],
   "source": [
    "cleaned_resumes = []\n",
    "\n",
    "for r in resumes:\n",
    "    cleaned = clean_text(r)\n",
    "    cleaned_resumes.append(cleaned)\n",
    "\n",
    "print(\"Total cleaned resumes:\", len(cleaned_resumes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a3f4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"\n",
    "We are looking for a Python Django developer with strong SQL skills.\n",
    "Experience with REST APIs and AWS is preferred.\n",
    "Knowledge of HTML, CSS, and JavaScript is a plus.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35f828d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look python django developer strong sql skill experience rest apis aw preferred knowledge html css javascript plus\n"
     ]
    }
   ],
   "source": [
    "cleaned_jd = clean_text(job_description)\n",
    "\n",
    "print(cleaned_jd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33a0e9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in c:\\programdata\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb06767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (3501, 38235)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Combine JD and resumes\n",
    "documents = [cleaned_jd] + cleaned_resumes\n",
    "\n",
    "# Fit and transform\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e01d6c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed similarity for 3500 resumes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Job description vector\n",
    "jd_vector=tfidf_matrix[0:1]\n",
    "# Resume vectors\n",
    "resume_vectors=tfidf_matrix[1:]\n",
    "# Compute similarity\n",
    "similarity_scores = cosine_similarity(jd_vector, resume_vectors).flatten()\n",
    "\n",
    "print(\"Computed similarity for\", len(similarity_scores), \"resumes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "815a8a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02124501 0.01867914 0.0797577  0.09754874 0.03935882 0.03947394\n",
      " 0.11927576 0.03479041 0.07400253 0.06189171]\n"
     ]
    }
   ],
   "source": [
    "print(similarity_scores[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac68d5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed skill scores for 3500 resumes\n"
     ]
    }
   ],
   "source": [
    "#Similarity score → semantic relevance\n",
    "#Skill score → requirement match\n",
    "\n",
    "\n",
    "from nlp.skill_extraction import extract_skills\n",
    "\n",
    "# Extract JD skills\n",
    "jd_skills = extract_skills(cleaned_jd)\n",
    "\n",
    "resume_skill_scores = []\n",
    "\n",
    "for r in cleaned_resumes:\n",
    "    skills = extract_skills(r)\n",
    "    \n",
    "    overlap = set(skills).intersection(set(jd_skills))\n",
    "    \n",
    "    score = len(overlap) / len(jd_skills) if jd_skills else 0\n",
    "    \n",
    "    resume_skill_scores.append(score)\n",
    "\n",
    "print(\"Computed skill scores for\", len(resume_skill_scores), \"resumes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffeb939",
   "metadata": {},
   "source": [
    "Calculating Total score   giving more priority to similarity score\n",
    "Similarity score → semantic relevance         \n",
    "Skill score → requirement match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c308bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final scores computed.\n"
     ]
    }
   ],
   "source": [
    "final_scores = []\n",
    "\n",
    "for sim, skill in zip(similarity_scores, resume_skill_scores):\n",
    "    final_scores.append(0.7 * sim + 0.3 * skill)\n",
    "\n",
    "print(\"Final scores computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51148506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 candidates scores:\n",
      "0.5130227262521225\n",
      "0.5000167994152296\n",
      "0.4876267235485146\n",
      "0.4736196537890567\n",
      "0.46508569995179533\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ranked_indices = np.argsort(final_scores)[::-1]\n",
    "\n",
    "print(\"Top 5 candidates scores:\")\n",
    "\n",
    "for i in ranked_indices[:5]:\n",
    "    print(final_scores[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dc96a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top candidate similarity: 0.3043181803601751\n",
      "Top candidate skill score: 1.0\n",
      "Top candidate final score: 0.5130227262521225\n",
      "\n",
      "Resume snippet:\n",
      "\n",
      "jessica claire      montgomery floor              resumesampleexamplecom professional summary year experience analysis design development management implementation standalone clientserver architecture base enterprise application software extensive knowledge python mysql django experience design code debug operation report datum analysis web application utilize python work mvw framework like django angular html css json excellent working experience agile scrum rally tfs rup waterfall methodology \n"
     ]
    }
   ],
   "source": [
    "top_idx = ranked_indices[0]\n",
    "\n",
    "print(\"Top candidate similarity:\", similarity_scores[top_idx])\n",
    "print(\"Top candidate skill score:\", resume_skill_scores[top_idx])\n",
    "print(\"Top candidate final score:\", final_scores[top_idx])\n",
    "\n",
    "print(\"\\nResume snippet:\\n\")\n",
    "print(cleaned_resumes[top_idx][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32fec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
